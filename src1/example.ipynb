{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "179be24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_ollama import ChatOllama\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_template(\n",
    "#     \"Question: {question}\\n\\nAnswer: Let's think step by step.\"\n",
    "# )\n",
    "\n",
    "# llm = ChatOllama(model=\"llama3.1\")  # or \"llama3.1:8b\"\n",
    "# chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# print(chain.invoke({\"question\": \"What is LangChain?\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d9e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install langchain-core langchain-community langchain-ollama\n",
    "# !pip3 install pdfplumber PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4cf8d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade langchain-community langgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45274c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import LLMWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cdbe0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Resume Analysis**\\n\\nUnfortunately, you didn't provide a resume for me to parse. Please share the resume, and I'll be happy to extract only the technologies and relevant experiences for you!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = LLMWrapper()\n",
    "llm.generate_response(\"What is LangChain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe9a0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m text1 = \u001b[33m\"\u001b[39m\u001b[33mArtificial intelligence is transforming healthcare by enabling faster diagnosis.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     32\u001b[39m text2 = \u001b[33m\"\u001b[39m\u001b[33mAI is revolutionizing medicine by assisting doctors with quicker diagnosis.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcompare_texts_ollama\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext2\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mcompare_texts_ollama\u001b[39m\u001b[34m(text1, text2, model)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompare_texts_ollama\u001b[39m(text1, text2, model=\u001b[33m\"\u001b[39m\u001b[33mllama3.1\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      4\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33mYou are a text comparison assistant. Compare the following two texts:\u001b[39m\n\u001b[32m      6\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m \u001b[33m4. Overall summary\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     result = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mollama\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.stdout.strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:556\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    558\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:1222\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1219\u001b[39m     endtime = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1221\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     stdout, stderr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1224\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1225\u001b[39m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:2102\u001b[39m, in \u001b[36mPopen._communicate\u001b[39m\u001b[34m(self, input, endtime, orig_timeout)\u001b[39m\n\u001b[32m   2099\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stderr:\n\u001b[32m   2100\u001b[39m     stderr = \u001b[38;5;28mself\u001b[39m._fileobj2output[\u001b[38;5;28mself\u001b[39m.stderr]\n\u001b[32m-> \u001b[39m\u001b[32m2102\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._input:\n\u001b[32m   2105\u001b[39m     input_view = \u001b[38;5;28mmemoryview\u001b[39m(\u001b[38;5;28mself\u001b[39m._input)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:2182\u001b[39m, in \u001b[36mPopen._save_input\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m   2180\u001b[39m \u001b[38;5;28mself\u001b[39m._input = \u001b[38;5;28minput\u001b[39m\n\u001b[32m   2181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m-> \u001b[39m\u001b[32m2182\u001b[39m     \u001b[38;5;28mself\u001b[39m._input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m(\u001b[38;5;28mself\u001b[39m.stdin.encoding,\n\u001b[32m   2183\u001b[39m                                      \u001b[38;5;28mself\u001b[39m.stdin.errors)\n",
      "\u001b[31mAttributeError\u001b[39m: 'bytes' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def compare_texts_ollama(text1, text2, model=\"llama3.1\"):\n",
    "    prompt = f\"\"\"\n",
    "You are a text comparison assistant. Compare the following two texts:\n",
    "\n",
    "Text 1:\n",
    "{text1}\n",
    "\n",
    "Text 2:\n",
    "{text2}\n",
    "\n",
    "Return the result in json format with the following sections:\n",
    "1. Similarity score (0â€“100)\n",
    "2. Key similarities\n",
    "3. Key differences\n",
    "4. Overall summary\n",
    "\"\"\"\n",
    "\n",
    "    result = subprocess.run(\n",
    "        [\"ollama\", \"run\", model],\n",
    "        input=prompt.encode(\"utf-8\"),\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    return result.stdout.strip()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text1 = \"Artificial intelligence is transforming healthcare by enabling faster diagnosis.\"\n",
    "text2 = \"AI is revolutionizing medicine by assisting doctors with quicker diagnosis.\"\n",
    "\n",
    "print(compare_texts_ollama(text1, text2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233a1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
